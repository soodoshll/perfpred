{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e43c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qidong/perfpred/torch_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519c43fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dgl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdgl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dgl\u001b[39m.\u001b[39m__version__\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "dgl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35354da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         raw_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m raw_data\n\u001b[0;32m----> 8\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m raw_data \u001b[39m=\u001b[39m load_data_raw(dataset_file)\n\u001b[1;32m     10\u001b[0m dur \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_file = 'nas_graphs.data'\n",
    "\n",
    "def load_data_raw(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        raw_data = pickle.load(f)\n",
    "    return raw_data\n",
    "\n",
    "t0 = time.time()\n",
    "raw_data = load_data_raw(dataset_file)\n",
    "dur = time.time() - t0\n",
    "\n",
    "print(f\"dataset loaded, cost {dur} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7db033c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# transform type node_type into onehot\u001b[39;00m\n\u001b[1;32m      6\u001b[0m n_ntypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_type, _, _, _, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mraw_data\u001b[49m:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     print(node_type)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     max_node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(node_type)\n\u001b[1;32m     10\u001b[0m     n_ntypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_ntypes, max_node_type)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "# construct graphs\n",
    "graphs = []\n",
    "labels = []\n",
    "\n",
    "# transform type node_type into onehot\n",
    "n_ntypes = 0\n",
    "for node_type, _, _, _, _ in raw_data:\n",
    "#     print(node_type)\n",
    "    max_node_type = max(node_type)\n",
    "    n_ntypes = max(n_ntypes, max_node_type)\n",
    "n_ntypes += 1\n",
    "\n",
    "for node_type, node_data, edge_list, edge_data, mem in raw_data:\n",
    "    edge_list_tensor = torch.LongTensor(edge_list)\n",
    "    node_type_tensor = torch.nn.functional.one_hot(torch.tensor(node_type), n_ntypes)\n",
    "    ndata = torch.stack(node_data)\n",
    "#     print(ndata.shape, node_type_tensor.shape)\n",
    "    ndata = torch.concat([node_type_tensor, ndata], dim=1)\n",
    "#     print(ndata.shape)\n",
    "    edata = torch.tensor(edge_data)\n",
    "    g = dgl.graph((edge_list_tensor[:, 0], edge_list_tensor[:, 1]))\n",
    "    g.ndata['feat'] = ndata\n",
    "    g.edata['feat'] = edata.float()\n",
    "    graphs.append(g)\n",
    "    labels.append(mem)\n",
    "    \n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "88c15616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup\n",
    "with open(\"nas_graphs_dgl.data\", \"wb\") as f:\n",
    "    pickle.dump([graphs, labels], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da50329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nas_graphs_dgl.data\", \"rb\") as f:\n",
    "    graphs, labels = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad5ff859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat': tensor([[      1, 1048576],\n",
       "        [      0, 1048576],\n",
       "        [      1, 1048576],\n",
       "        ...,\n",
       "        [      0,   16384],\n",
       "        [      0,  262144],\n",
       "        [      0,       0]])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74bf0abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 422.,  542.,  477., 1382.,  813.,  669., 1272.,  320.,  297.,\n",
       "         209.]),\n",
       " array([ 770.,  848.,  926., 1004., 1082., 1160., 1238., 1316., 1394.,\n",
       "        1472., 1550.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "num_nodes = [g.num_nodes() for g in graphs]\n",
    "num_edges = [g.num_edges() for g in graphs]\n",
    "\n",
    "plt.hist(num_nodes)\n",
    "plt.hist(num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86570602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "num_ndata = graphs[0].ndata['feat'].shape[1]\n",
    "num_edata = graphs[0].edata['feat'].shape[1]\n",
    "\n",
    "max_ndata = []\n",
    "min_ndata = []\n",
    "max_edata = []\n",
    "min_edata = []\n",
    "\n",
    "for ndata_id in range(num_ndata):\n",
    "    max_v = graphs[0].ndata['feat'][0, ndata_id]\n",
    "    min_v = graphs[0].ndata['feat'][0, ndata_id]\n",
    "    for g in graphs:\n",
    "        max_v = max(max_v, torch.max(g.ndata['feat'][:, ndata_id]))\n",
    "        min_v = min(min_v, torch.min(g.ndata['feat'][:, ndata_id]))\n",
    "    if max_v != min_v:\n",
    "        for g in graphs:\n",
    "            g.ndata['feat'][:, ndata_id] = (g.ndata['feat'][:, ndata_id] - min_v)/(max_v - min_v)\n",
    "    max_ndata.append(max_v)\n",
    "    min_ndata.append(min_v)\n",
    "            \n",
    "for edata_id in range(num_edata):\n",
    "    max_v = graphs[0].edata['feat'][0, edata_id]\n",
    "    min_v = graphs[0].edata['feat'][0, edata_id]\n",
    "    for g in graphs:\n",
    "        max_v = max(max_v, torch.max(g.edata['feat'][:, edata_id]))\n",
    "        min_v = min(min_v, torch.min(g.edata['feat'][:, edata_id]))\n",
    "    if max_v != min_v:\n",
    "        for g in graphs:\n",
    "            g.edata['feat'][:, edata_id] = (g.edata['feat'][:, edata_id] - min_v)/(max_v - min_v)\n",
    "    max_edata.append(max_v)\n",
    "    min_edata.append(min_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278d1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ANEELayer(nn.Module):\n",
    "    def __init__(self, ndim, edim, nlayers):\n",
    "        super(ANEELayer, self).__init__()\n",
    "        self.ndim = ndim\n",
    "        self.edim = edim\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "        self.Wu = nn.Parameter(torch.randn((ndim, ndim)))\n",
    "        self.We = nn.Parameter(torch.randn((edim, edim)))\n",
    "        self.a = nn.Parameter(torch.randn(2 * ndim))\n",
    "        self.Wm = nn.Parameter(torch.randn(edim))\n",
    "        \n",
    "        self.W = nn.Parameter(torch.randn((ndim, )))\n",
    "    \n",
    "    def forward(self, g, ndata, edata):\n",
    "        for i in range(self.nlayers):\n",
    "            ndata = F.leaky_relu(ndata.matmul(self.Wu))\n",
    "            u, v = g.edges(form='uv')\n",
    "            uv_feat = torch.concat([ndata[u, :], ndata[v, :]], dim=-1)\n",
    "    #         print(uv_feat.shape)\n",
    "    #         print(edata.matmul(self.We).shape)\n",
    "            new_edata = F.sigmoid(uv_feat.matmul(self.a).unsqueeze(1) * (edata.matmul(self.We)))\n",
    "    #         Wme = F.softmax(new_edata.matmul(self.Wm))\n",
    "            Wme = F.sigmoid(new_edata.matmul(self.Wm))\n",
    "            new_ndata = dgl.ops.u_mul_e_sum(g, ndata, Wme)\n",
    "            new_ndata = F.leaky_relu(new_ndata)\n",
    "#             print(new_ndata.shape)\n",
    "    #         print(new_edata.shape)\n",
    "            ndata = new_ndata\n",
    "            edata = new_edata\n",
    "        ndata_sum = ndata.sum(dim=0)\n",
    "        out = ndata_sum.matmul(self.W)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0de9c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1200.5023, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ANEELayer(44, 2, 2)\n",
    "model(graphs[0], graphs[0].ndata['feat'], graphs[0].edata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e46b75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:30<00:00, 145.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98378974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 156.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27533457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 157.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14721298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 157.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13762957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:29<00:00, 153.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12682308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 156.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11694984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 157.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10841072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 156.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10072584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:29<00:00, 153.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09329142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4482/4482 [00:28<00:00, 155.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08676987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "model = ANEELayer(44, 2, 2)\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "indices = np.random.permutation(range(len(graphs)))\n",
    "n_train = int(0.7 * len(graphs))\n",
    "\n",
    "graphs_gpu = [g.to(device) for g in graphs]\n",
    "\n",
    "for epoch in range(10):\n",
    "    errs = []\n",
    "    for i in tqdm(indices[:n_train]):\n",
    "        g = graphs_gpu[i]\n",
    "        label = labels[i].to(device)\n",
    "        optim.zero_grad()\n",
    "        out = model(g, g.ndata['feat'], g.edata['feat'])\n",
    "        err = torch.abs(out - label) / label\n",
    "        errs.append(err.cpu().detach().numpy())\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    #     print(loss)\n",
    "    print(np.mean(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb551018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1921/1921 [00:13<00:00, 145.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.080651365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "for i in tqdm(indices[n_train:]):\n",
    "    g = graphs_gpu[i]\n",
    "    label = labels[i].to(device)\n",
    "    optim.zero_grad()\n",
    "    out = model(g, g.ndata['feat'], g.edata['feat'])\n",
    "    err = torch.abs(out - label) / label\n",
    "    errs.append(err.cpu().detach().numpy())\n",
    "    loss = loss_fn(out, label)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "#     print(loss)\n",
    "print(np.mean(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b9df1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a01faa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trace import Graph\n",
    "example = torchvision.models.resnet18()\n",
    "example.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3528724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((32, 3, 128, 128), device=device)\n",
    "out = example(inputs)\n",
    "raw_g = Graph(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2bbb28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type, node_data, edge_list, edge_data = raw_g.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db4cd3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08ec10d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([437, 44])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].ndata['feat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f7466b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   1,   1,   2,   2,   3,   3,   3,   3,   4,   4,   5,   5,\n",
       "          6,   6,   7,   7,   8,   8,   9,   9,  10,  10,  10,  10,  11,  11,\n",
       "         12,  12,  13,  13,  14,  14,  15,  15,  16,  16,  17,  17,  17,  17,\n",
       "         18,  18,  19,  19,  20,  20,  21,  21,  22,  22,  23,  23,  24,  24,\n",
       "         25,  25,  26,  26,  26,  26,  27,  27,  28,  28,  29,  29,  30,  30,\n",
       "         31,  31,  32,  32,  33,  33,  33,  33,  34,  34,  35,  35,  36,  36,\n",
       "         37,  37,  38,  38,  39,  39,  40,  40,  41,  41,  42,  42,  42,  42,\n",
       "         43,  43,  44,  44,  45,  45,  46,  46,  47,  47,  48,  48,  49,  49,\n",
       "         49,  49,  50,  50,  51,  51,  52,  52,  53,  53,  54,  54,  55,  55,\n",
       "         56,  56,  57,  57,  58,  58,  58,  58,  59,  59,  60,  60,  61,  61,\n",
       "         62,  62,  63,  63,  64,  64,  65,  65,  66,  66,  69,  69,  70,  70,\n",
       "         71,  71,  72,  72,  72,  73,  73,  74,  74,  75,  75,  76,  76,  77,\n",
       "         77,  78,  78,  79,  79,  79,  80,  80,  81,  81,  82,  82,  83,  83,\n",
       "         84,  84,  85,  85,  86,  86,  86,  87,  87,  88,  88,  89,  89,  90,\n",
       "         90,  91,  91,  92,  92,  93,  93,  93,  94,  94,  95,  95,  96,  96,\n",
       "         97,  97,  98,  98,  99,  99, 100, 100, 100, 101, 101, 102, 102, 103,\n",
       "        103, 104, 104, 105, 105, 106, 106, 107, 107, 107, 108, 108, 109, 109,\n",
       "        110, 110, 111, 111, 112, 112, 113, 113, 114, 114, 114, 115, 115, 116,\n",
       "        116, 117, 117, 118, 118, 119, 119, 120, 120, 121, 121, 121, 122, 122,\n",
       "        123, 123, 124, 124, 125, 125, 126, 126, 127, 127, 128, 128, 129, 129,\n",
       "        130, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135, 136, 136])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list_tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba999add",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_tensor = torch.LongTensor(edge_list)\n",
    "node_type_tensor = torch.nn.functional.one_hot(torch.tensor(node_type), 24)\n",
    "ndata = torch.stack(node_data)\n",
    "ndata = torch.concat([node_type_tensor, ndata], dim=1)\n",
    "edata = torch.tensor(edge_data)\n",
    "\n",
    "g = dgl.graph((edge_list_tensor[:, 0], edge_list_tensor[:, 1]))\n",
    "\n",
    "g.ndata['feat'] = ndata\n",
    "g.edata['feat'] = edata.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "704a5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "#max_ndata = []\n",
    "#min_ndata = []\n",
    "#max_edata = []\n",
    "#min_edata = []\n",
    "\n",
    "for i in range(len(max_ndata)):\n",
    "    if max_ndata[i] != min_ndata[i]:\n",
    "        g.ndata['feat'][:, i] = (g.ndata['feat'][:, i] - min_ndata[i]) / (max_ndata[i] - min_ndata[i])\n",
    "        \n",
    "for i in range(len(max_edata)):\n",
    "    if max_edata[i] != min_edata[i]:\n",
    "        g.edata['feat'][:, i] = (g.edata['feat'][:, i] - min_edata[i]) / (max_edata[i] - min_edata[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21f28bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-288.9028, device='cuda:0', grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = g.to(device)\n",
    "model(g, g.ndata['feat'].cuda(), g.edata['feat'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26125c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f06f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('torch_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "21b3263d2991743e4a43220dd74aeccbe181f5d910cbd8cafed6ccc636e1c9d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
